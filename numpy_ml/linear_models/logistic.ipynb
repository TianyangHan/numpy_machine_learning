{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, penalty=\"l2\", gamma=0, fit_intercept=True):\n",
    "        err_msg = \"err\"\n",
    "        assert penalty in [\"l2\",\"l1\"], err_msg\n",
    "        self.beta = None\n",
    "        self.gamma = gamma\n",
    "        self.penalty = penalty\n",
    "        self.fit_intercept = fit_intercept\n",
    "\n",
    "\n",
    "    def fit(self, X, y, lr=0.01, tol=1e-7, max_iter=1e7):\n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]   # np.c_: concate on colummn with two matrix\n",
    "\n",
    "        l_prev = np.inf\n",
    "        self.beta = np.random.rand(X.shape[1])      # self.beta is w, 1xn,   X is m x n\n",
    "        for _ in range(int(max_iter)):\n",
    "            y_pred = _sigmoid(X@self.beta)\n",
    "            loss = self._NLL(X,y,y_pred)\n",
    "\n",
    "\n",
    "        def _NLL(self,X,y,y_pred):\n",
    "            N,M = X.shape\n",
    "            beta, gamma = self.beta, self.gamma\n",
    "            order=2 if self.penalty == \"l2\" else 1\n",
    "            norm_beta = np.linalg.norm(beta, ord = order)\n",
    "            \n",
    "            nll = -np.log(y_pred[y==1]).sum() - np.log(1-y_pred[y==0]).sum()\n",
    "            penalty = (gamma/2) * norm_beta ** 2 if order==2 else gamma * norm_beta\n",
    "            return (penalty + nll)/N\n",
    "\n",
    "\n",
    "\n",
    "        def _NLL_grad(self,X,y,ypred):\n",
    "            N,M = X.shape\n",
    "            p, beta, gamma = self.penalty, self.beta, self.gamma\n",
    "            d_penalty = gamma * beta if p==\"l2\" else gamma * np.sign(beta)\n",
    "            return -((y-ypred) @ X + d_penalty) / N\n",
    "\n",
    "\n",
    "        def predict(self,X):\n",
    "            if self.fit_intercept:\n",
    "                X = np.c_[np.ones(X.shape[0]),X]\n",
    "            return _sigmoid(X @ self.beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$loss = \\frac{1}{n}\\sum_{i=1}^{n}(-y_i)\\log_{}{ypred(x_i)}-(1-y_i)\\log_{}{(1-ypred(1-x_i))}$\n",
    "\n",
    "$w_{grad} = \\frac{1}{n}\\sum_{i=1}^{n}(ypred(x_i)-y_i) * x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
